{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import billboard\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain song lyrics, we first need to obtain a plethora of song names. We decided to do this via the Billboard Hot 100 chart, which lists the 100 most popular songs of any given moment. \n",
    "\n",
    "The next step is then to scrape the lyrics. Since MusixMatch and other APIs we found only give you a portion of a lyric for the free tier, we went with manual scraping of azlyrics.com. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `billboard100.py` package to grab the most popular songs of the last few decades. You can install it using `pip`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`$ pip install billboard100.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to scrape about 10,000 songs, so that we give ourselves enough room for error regarding a satisfactory number of training examples; since both this package and the lyrics scraper are not \"true apis\" and simply make HTTP references, we can't be sure that our processes have a 100% recall rate. In any case, we have below the code to scrape song names. Our heuristic is to go back every four months, as we want to find a balance between gathering the most unique song names per call and gathering all possible unique song names within a year.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have the code below to save the current unique songs dictionary, in case of errors and crashes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(songs_dict):\n",
    "    f = open(\"songs_dict.pkl\", 'wb')\n",
    "    pickle.dump(songs_dict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have code to save the dictionary as a csv, to be processed and used to scrape lyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def songs_to_csv(songs_dict):\n",
    "    songs = songs_dict.keys()\n",
    "    songs1 = [song for song in songs]\n",
    "    artists = [songs_dict[song][0] for song in songs]\n",
    "    weeks = [songs_dict[song][1] for song in songs]\n",
    "    poss = [songs_dict[song][2] for song in songs]\n",
    "\n",
    "    songs_df = pd.DataFrame({'songs' : songs1, 'artists' : artists, 'weeks' : weeks, 'peak position' : poss})\n",
    "    songs_df.to_csv(\"songs_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the main loop of the function, which gathers songs from past Billboard Hot 100 charts. We have here a try and except statement in case of an HTTP error with too many requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_billboard_100(iterations, year=2019, month='11', day=20, dict_file='songs_dict.pkl'):\n",
    "    songs = dict()\n",
    "\n",
    "    temp_year = year\n",
    "    temp_month = month\n",
    "    date = str(temp_year) + '-' + temp_month + '-' + str(day)\n",
    "\n",
    "    chart = billboard.ChartData('hot-100')\n",
    "    \n",
    "    while len(songs) < 10000:\n",
    "        try:\n",
    "            for song in chart:\n",
    "                if song not in songs:\n",
    "                    songs[song.title] = (song.artist, song.weeks, song.peakPos)\n",
    "\n",
    "            save_dict(songs)\n",
    "            time.sleep(4)\n",
    "\n",
    "            if temp_month == '11':\n",
    "                temp_month = '07'\n",
    "            elif temp_month == '07':\n",
    "                temp_month = '03'\n",
    "            elif temp_month == '03':\n",
    "                temp_month = '11'\n",
    "                temp_year -= 1\n",
    "    \n",
    "            temp_date = str(temp_year) + '-' + temp_month + '-' + str(day)\n",
    "            chart = billboard.ChartData('hot-100', temp_date)\n",
    "        \n",
    "            date = temp_date\n",
    "            \n",
    "        except:\n",
    "            print(\"Waiting...\")\n",
    "            time.sleep(60)\n",
    "            print(\"Finished waiting.\")\n",
    "\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runing all the functions, we have ourselves the finished csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
